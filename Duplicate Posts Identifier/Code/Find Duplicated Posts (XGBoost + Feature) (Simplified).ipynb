{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alchemist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alchemist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, ngrams\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use XGBoost to test of the above features do increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# gpu_boost: If true, use GPU boost. Note: Using GPU boost may result in slight worse accuracy than using only CPU for calculation\n",
    "# data_oversample: If true, make positive rate decrease from 0.369 to 0.17 (original test data has 0.17 positive rate), this should NOT make sense since we have used different test data and the positive rate in test data is the same as the training data\n",
    "# objective_hinge: If true, make \"accuracy\" as the objective (achieve highest accuracy) and the output will be boolean values (0 or 1). If false, make \"logloss\" as the objective (achieve lowest logloss) and the output will be float values (between 0 and 1) and needs to be converted to boolean values (< 0.5 means 0 and 1 otherwise)\n",
    "# output_csv: If true, output corresponding csv file. Note: May overwrite previous file, please double check before running\n",
    "\n",
    "def xgb_model(train_df, test_df, data_clean_type, gpu_boost = True, data_oversample = False, objective_hinge = True, output_csv = True):\n",
    "    if data_oversample: \n",
    "        # Rebalance the data to make it closer to the test set\n",
    "        pos_boostrap_sample = train_df[train_df[\"is_duplicate\"] == 0].sample(n = 500000, replace = True)\n",
    "        rebalanced_df = pd.concat((pos_boostrap_sample, train_df))\n",
    "        print(\"Positive rate: {}%\".format(round(rebalanced_df['is_duplicate'].value_counts()[1] / (rebalanced_df['is_duplicate'].value_counts()[0] + rebalanced_df['is_duplicate'].value_counts()[1]), 3)))\n",
    "        \n",
    "        x_train = pd.DataFrame()\n",
    "        x_test = pd.DataFrame()\n",
    "        y_train = pd.DataFrame()\n",
    "        y_test = pd.DataFrame()\n",
    "\n",
    "        x_train['unigrams_common_count'] = rebalanced_df['unigrams_common_count']\n",
    "        x_train['unigrams_common_ratio'] = rebalanced_df['unigrams_common_ratio']\n",
    "        x_train['q1_q2_intersect'] = rebalanced_df['q1_q2_intersect']\n",
    "        x_train['q1_freq'] = rebalanced_df['q1_freq']\n",
    "        x_train['q2_freq'] = rebalanced_df['q2_freq']\n",
    "        x_train['word_match'] = rebalanced_df['word_match']\n",
    "        x_train['tfidf_word_match'] = rebalanced_df['tfidf_word_match']\n",
    "\n",
    "        x_test['unigrams_common_count'] = test_df['unigrams_common_count']\n",
    "        x_test['unigrams_common_ratio'] = test_df['unigrams_common_ratio']\n",
    "        x_test['q1_q2_intersect'] = test_df['q1_q2_intersect']\n",
    "        x_test['q1_freq'] = test_df['q1_freq']\n",
    "        x_test['q2_freq'] = test_df['q2_freq']\n",
    "        x_test['word_match'] = test_df['word_match']\n",
    "        x_test['tfidf_word_match'] = test_df['tfidf_word_match']\n",
    "\n",
    "        y_train['is_duplicate'] = rebalanced_df['is_duplicate']\n",
    "        y_test['is_duplicate (Ture Value)'] = test_df['is_duplicate (Ture Value)']\n",
    "        \n",
    "    else:\n",
    "        print(\"Positive rate: {}%\".format(round(train_df['is_duplicate'].value_counts()[1] / (train_df['is_duplicate'].value_counts()[0] + train_df['is_duplicate'].value_counts()[1]), 3)))\n",
    "        x_train = pd.DataFrame()\n",
    "        x_test = pd.DataFrame()\n",
    "        y_train = pd.DataFrame()\n",
    "        y_test = pd.DataFrame()\n",
    "\n",
    "        x_train['unigrams_common_count'] = train_df['unigrams_common_count']\n",
    "        x_train['unigrams_common_ratio'] = train_df['unigrams_common_ratio']\n",
    "        x_train['q1_q2_intersect'] = train_df['q1_q2_intersect']\n",
    "        x_train['q1_freq'] = train_df['q1_freq']\n",
    "        x_train['q2_freq'] = train_df['q2_freq']\n",
    "        x_train['word_match'] = train_df['word_match']\n",
    "        x_train['tfidf_word_match'] = train_df['tfidf_word_match']\n",
    "\n",
    "        x_test['unigrams_common_count'] = test_df['unigrams_common_count']\n",
    "        x_test['unigrams_common_ratio'] = test_df['unigrams_common_ratio']\n",
    "        x_test['q1_q2_intersect'] = test_df['q1_q2_intersect']\n",
    "        x_test['q1_freq'] = test_df['q1_freq']\n",
    "        x_test['q2_freq'] = test_df['q2_freq']\n",
    "        x_test['word_match'] = test_df['word_match']\n",
    "        x_test['tfidf_word_match'] = test_df['tfidf_word_match']\n",
    "\n",
    "        y_train['is_duplicate'] = train_df['is_duplicate']\n",
    "        y_test['is_duplicate (Ture Value)'] = test_df['is_duplicate (Ture Value)']\n",
    "    \n",
    "    # Finally, we split some of the data off for validation\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    # The following parameters may be fine-tuned in the future\n",
    "    #params[\"eta\"] = 0.02\n",
    "    #params[\"gamma\"] = 0\n",
    "    #params[\"max_depth\"] = 6\n",
    "    #params[\"min_child_weight\"] = 4\n",
    "    #params[\"max_bin\"] = 256\n",
    "    #params[\"subsample\"] = 0.8\n",
    "    #params[\"colsample_bytree\"] = 0.9\n",
    "\n",
    "    if objective_hinge:\n",
    "        params['objective'] = 'binary:hinge'\n",
    "        params['eval_metric'] = 'error'\n",
    "    else:\n",
    "        params[\"objective\"] = \"binary:logistic\"\n",
    "        params[\"eval_metric\"] = \"logloss\"\n",
    "\n",
    "    if gpu_boost:\n",
    "        params[\"tree_method\"] = \"gpu_hist\"\n",
    "        bst = xgb.train(params, d_train, 100000, watchlist, early_stopping_rounds=2000, verbose_eval=10)\n",
    "    else:\n",
    "        bst = xgb.train(params, d_train, 100000, watchlist, early_stopping_rounds=200, verbose_eval=10)\n",
    "        \n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "    p_test = bst.predict(d_test)\n",
    "    \n",
    "    if not objective_hinge:\n",
    "        # Convert percentage to binary predictions\n",
    "        result = []\n",
    "        for i in p_test:\n",
    "            if i < 0.5:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        result = np.array(result)\n",
    "        sub = pd.DataFrame()\n",
    "        sub['test_id'] = test_df['test_id']\n",
    "        sub['is_duplicate'] = result\n",
    "         \n",
    "        # Get the accuracy on the test data\n",
    "        true_values = test_df[\"is_duplicate (Ture Value)\"]\n",
    "\n",
    "        score = 0\n",
    "        for i in range(0, len(result)):\n",
    "            if result[i] == true_values.tolist()[i]:\n",
    "                score = score + 1\n",
    "        accuracy = score / len(result)\n",
    "        print(\"Accuracy on test data: {}%\".format(round(accuracy*100, 3)))\n",
    "    else:\n",
    "        sub = pd.DataFrame()\n",
    "        sub['test_id'] = test_df['test_id']\n",
    "        sub['is_duplicate'] = p_test\n",
    "        \n",
    "        # Get the accuracy on the test data\n",
    "        true_values = test_df[\"is_duplicate (Ture Value)\"]\n",
    "\n",
    "        score = 0\n",
    "        for i in range(0, len(p_test)):\n",
    "            if p_test[i] == true_values.tolist()[i]:\n",
    "                score = score + 1\n",
    "        accuracy = score / len(p_test)\n",
    "        print(\"Accuracy on test data: {}%\".format(round(accuracy*100, 3)))\n",
    "    \n",
    "    file_name = 'xgb_with_features' + data_clean_type\n",
    "    if (gpu_boost):\n",
    "        file_name = file_name + '(gpu_boost)'\n",
    "    if (data_oversample):\n",
    "        file_name = file_name + '(data_oversample)'\n",
    "    if (objective_hinge):\n",
    "        file_name = file_name + '(objective_accuracy)'\n",
    "    else:\n",
    "        file_name = file_name + '(objective_logloss)'\n",
    "    \n",
    "    if output_csv:\n",
    "        sub.to_csv(file_name + '.csv', index=False)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.369%\n",
      "[0]\ttrain-error:0.63048\tvalid-error:0.63099\n",
      "[10]\ttrain-error:0.13652\tvalid-error:0.13686\n",
      "[20]\ttrain-error:0.13363\tvalid-error:0.13464\n",
      "[30]\ttrain-error:0.13273\tvalid-error:0.13342\n",
      "[40]\ttrain-error:0.13202\tvalid-error:0.13274\n",
      "[50]\ttrain-error:0.13177\tvalid-error:0.13279\n",
      "[60]\ttrain-error:0.13154\tvalid-error:0.13224\n",
      "[70]\ttrain-error:0.13138\tvalid-error:0.13235\n",
      "[80]\ttrain-error:0.13130\tvalid-error:0.13229\n",
      "[90]\ttrain-error:0.13100\tvalid-error:0.13215\n",
      "[100]\ttrain-error:0.13092\tvalid-error:0.13203\n",
      "[110]\ttrain-error:0.13072\tvalid-error:0.13180\n",
      "[120]\ttrain-error:0.13077\tvalid-error:0.13176\n",
      "[130]\ttrain-error:0.13048\tvalid-error:0.13149\n",
      "[140]\ttrain-error:0.13045\tvalid-error:0.13167\n",
      "[150]\ttrain-error:0.13044\tvalid-error:0.13150\n",
      "[160]\ttrain-error:0.13037\tvalid-error:0.13142\n",
      "[170]\ttrain-error:0.13029\tvalid-error:0.13156\n",
      "[180]\ttrain-error:0.13021\tvalid-error:0.13154\n",
      "[190]\ttrain-error:0.13020\tvalid-error:0.13150\n",
      "[200]\ttrain-error:0.13017\tvalid-error:0.13161\n",
      "[210]\ttrain-error:0.13001\tvalid-error:0.13151\n",
      "[220]\ttrain-error:0.12982\tvalid-error:0.13149\n",
      "[230]\ttrain-error:0.12977\tvalid-error:0.13141\n",
      "[240]\ttrain-error:0.12968\tvalid-error:0.13150\n",
      "[250]\ttrain-error:0.12967\tvalid-error:0.13140\n",
      "[260]\ttrain-error:0.12959\tvalid-error:0.13129\n",
      "[270]\ttrain-error:0.12953\tvalid-error:0.13099\n",
      "[280]\ttrain-error:0.12932\tvalid-error:0.13100\n",
      "[290]\ttrain-error:0.12921\tvalid-error:0.13103\n",
      "[300]\ttrain-error:0.12920\tvalid-error:0.13119\n",
      "[310]\ttrain-error:0.12910\tvalid-error:0.13089\n",
      "[320]\ttrain-error:0.12912\tvalid-error:0.13094\n",
      "[330]\ttrain-error:0.12904\tvalid-error:0.13114\n",
      "[340]\ttrain-error:0.12888\tvalid-error:0.13120\n",
      "[350]\ttrain-error:0.12882\tvalid-error:0.13111\n",
      "[360]\ttrain-error:0.12883\tvalid-error:0.13100\n",
      "[370]\ttrain-error:0.12884\tvalid-error:0.13103\n",
      "[380]\ttrain-error:0.12878\tvalid-error:0.13105\n",
      "[390]\ttrain-error:0.12868\tvalid-error:0.13071\n",
      "[400]\ttrain-error:0.12866\tvalid-error:0.13066\n",
      "[410]\ttrain-error:0.12868\tvalid-error:0.13070\n",
      "[420]\ttrain-error:0.12865\tvalid-error:0.13070\n",
      "[430]\ttrain-error:0.12870\tvalid-error:0.13069\n",
      "[440]\ttrain-error:0.12864\tvalid-error:0.13057\n",
      "[450]\ttrain-error:0.12852\tvalid-error:0.13069\n",
      "[460]\ttrain-error:0.12862\tvalid-error:0.13089\n",
      "[470]\ttrain-error:0.12847\tvalid-error:0.13076\n",
      "[480]\ttrain-error:0.12841\tvalid-error:0.13082\n",
      "[490]\ttrain-error:0.12839\tvalid-error:0.13094\n",
      "[500]\ttrain-error:0.12839\tvalid-error:0.13079\n",
      "[510]\ttrain-error:0.12839\tvalid-error:0.13075\n",
      "[520]\ttrain-error:0.12837\tvalid-error:0.13085\n",
      "[530]\ttrain-error:0.12830\tvalid-error:0.13086\n",
      "[540]\ttrain-error:0.12833\tvalid-error:0.13093\n",
      "[550]\ttrain-error:0.12828\tvalid-error:0.13089\n",
      "[560]\ttrain-error:0.12818\tvalid-error:0.13082\n",
      "[570]\ttrain-error:0.12823\tvalid-error:0.13079\n",
      "[580]\ttrain-error:0.12817\tvalid-error:0.13076\n",
      "[590]\ttrain-error:0.12807\tvalid-error:0.13079\n",
      "[600]\ttrain-error:0.12808\tvalid-error:0.13075\n",
      "[610]\ttrain-error:0.12805\tvalid-error:0.13074\n",
      "[620]\ttrain-error:0.12794\tvalid-error:0.13065\n",
      "[630]\ttrain-error:0.12798\tvalid-error:0.13057\n",
      "[640]\ttrain-error:0.12785\tvalid-error:0.13055\n",
      "[650]\ttrain-error:0.12781\tvalid-error:0.13044\n",
      "[660]\ttrain-error:0.12777\tvalid-error:0.13053\n",
      "[670]\ttrain-error:0.12772\tvalid-error:0.13046\n",
      "[680]\ttrain-error:0.12768\tvalid-error:0.13044\n",
      "[690]\ttrain-error:0.12762\tvalid-error:0.13050\n",
      "[700]\ttrain-error:0.12762\tvalid-error:0.13039\n",
      "[710]\ttrain-error:0.12757\tvalid-error:0.13045\n",
      "[720]\ttrain-error:0.12751\tvalid-error:0.13061\n",
      "[730]\ttrain-error:0.12751\tvalid-error:0.13062\n",
      "[740]\ttrain-error:0.12745\tvalid-error:0.13060\n",
      "[750]\ttrain-error:0.12746\tvalid-error:0.13060\n",
      "[760]\ttrain-error:0.12749\tvalid-error:0.13069\n",
      "[770]\ttrain-error:0.12745\tvalid-error:0.13076\n",
      "[780]\ttrain-error:0.12746\tvalid-error:0.13066\n",
      "[790]\ttrain-error:0.12752\tvalid-error:0.13080\n",
      "[800]\ttrain-error:0.12742\tvalid-error:0.13070\n",
      "[810]\ttrain-error:0.12737\tvalid-error:0.13064\n",
      "[820]\ttrain-error:0.12732\tvalid-error:0.13064\n",
      "[830]\ttrain-error:0.12726\tvalid-error:0.13060\n",
      "[840]\ttrain-error:0.12713\tvalid-error:0.13069\n",
      "[850]\ttrain-error:0.12719\tvalid-error:0.13076\n",
      "[860]\ttrain-error:0.12718\tvalid-error:0.13064\n",
      "[870]\ttrain-error:0.12717\tvalid-error:0.13061\n",
      "[880]\ttrain-error:0.12713\tvalid-error:0.13066\n",
      "[890]\ttrain-error:0.12712\tvalid-error:0.13066\n",
      "[900]\ttrain-error:0.12712\tvalid-error:0.13053\n",
      "[910]\ttrain-error:0.12706\tvalid-error:0.13054\n",
      "[920]\ttrain-error:0.12703\tvalid-error:0.13059\n",
      "[930]\ttrain-error:0.12702\tvalid-error:0.13060\n",
      "[940]\ttrain-error:0.12702\tvalid-error:0.13055\n",
      "[950]\ttrain-error:0.12700\tvalid-error:0.13044\n",
      "[960]\ttrain-error:0.12690\tvalid-error:0.13051\n",
      "[970]\ttrain-error:0.12687\tvalid-error:0.13054\n",
      "[980]\ttrain-error:0.12685\tvalid-error:0.13041\n",
      "[990]\ttrain-error:0.12683\tvalid-error:0.13057\n",
      "[1000]\ttrain-error:0.12685\tvalid-error:0.13068\n",
      "[1010]\ttrain-error:0.12681\tvalid-error:0.13062\n",
      "[1020]\ttrain-error:0.12690\tvalid-error:0.13090\n",
      "[1030]\ttrain-error:0.12681\tvalid-error:0.13082\n",
      "[1040]\ttrain-error:0.12668\tvalid-error:0.13062\n",
      "[1050]\ttrain-error:0.12674\tvalid-error:0.13078\n",
      "[1060]\ttrain-error:0.12669\tvalid-error:0.13051\n",
      "[1070]\ttrain-error:0.12676\tvalid-error:0.13080\n",
      "[1080]\ttrain-error:0.12666\tvalid-error:0.13082\n",
      "[1090]\ttrain-error:0.12662\tvalid-error:0.13071\n",
      "[1100]\ttrain-error:0.12649\tvalid-error:0.13065\n",
      "[1110]\ttrain-error:0.12656\tvalid-error:0.13079\n",
      "[1120]\ttrain-error:0.12651\tvalid-error:0.13086\n",
      "[1130]\ttrain-error:0.12643\tvalid-error:0.13084\n",
      "[1140]\ttrain-error:0.12636\tvalid-error:0.13062\n",
      "[1150]\ttrain-error:0.12639\tvalid-error:0.13085\n",
      "[1160]\ttrain-error:0.12631\tvalid-error:0.13054\n",
      "[1170]\ttrain-error:0.12629\tvalid-error:0.13062\n",
      "[1180]\ttrain-error:0.12632\tvalid-error:0.13059\n",
      "[1190]\ttrain-error:0.12622\tvalid-error:0.13055\n",
      "[1200]\ttrain-error:0.12623\tvalid-error:0.13064\n",
      "[1210]\ttrain-error:0.12624\tvalid-error:0.13065\n",
      "[1220]\ttrain-error:0.12618\tvalid-error:0.13069\n",
      "[1230]\ttrain-error:0.12624\tvalid-error:0.13065\n",
      "[1240]\ttrain-error:0.12622\tvalid-error:0.13057\n",
      "[1250]\ttrain-error:0.12615\tvalid-error:0.13075\n",
      "[1260]\ttrain-error:0.12612\tvalid-error:0.13074\n",
      "[1270]\ttrain-error:0.12614\tvalid-error:0.13066\n",
      "[1280]\ttrain-error:0.12605\tvalid-error:0.13050\n",
      "[1290]\ttrain-error:0.12607\tvalid-error:0.13061\n",
      "[1300]\ttrain-error:0.12607\tvalid-error:0.13064\n",
      "[1310]\ttrain-error:0.12601\tvalid-error:0.13057\n",
      "[1320]\ttrain-error:0.12592\tvalid-error:0.13057\n",
      "[1330]\ttrain-error:0.12595\tvalid-error:0.13040\n",
      "[1340]\ttrain-error:0.12597\tvalid-error:0.13050\n",
      "[1350]\ttrain-error:0.12588\tvalid-error:0.13051\n",
      "[1360]\ttrain-error:0.12586\tvalid-error:0.13056\n",
      "[1370]\ttrain-error:0.12586\tvalid-error:0.13061\n",
      "[1380]\ttrain-error:0.12582\tvalid-error:0.13060\n",
      "[1390]\ttrain-error:0.12576\tvalid-error:0.13061\n",
      "[1400]\ttrain-error:0.12567\tvalid-error:0.13061\n",
      "[1410]\ttrain-error:0.12566\tvalid-error:0.13049\n",
      "[1420]\ttrain-error:0.12566\tvalid-error:0.13055\n",
      "[1430]\ttrain-error:0.12556\tvalid-error:0.13039\n",
      "[1440]\ttrain-error:0.12557\tvalid-error:0.13044\n",
      "[1450]\ttrain-error:0.12555\tvalid-error:0.13045\n",
      "[1460]\ttrain-error:0.12548\tvalid-error:0.13039\n",
      "[1470]\ttrain-error:0.12547\tvalid-error:0.13041\n",
      "[1480]\ttrain-error:0.12546\tvalid-error:0.13037\n",
      "[1490]\ttrain-error:0.12547\tvalid-error:0.13048\n",
      "[1500]\ttrain-error:0.12550\tvalid-error:0.13060\n",
      "[1510]\ttrain-error:0.12550\tvalid-error:0.13074\n",
      "[1520]\ttrain-error:0.12545\tvalid-error:0.13075\n",
      "[1530]\ttrain-error:0.12543\tvalid-error:0.13081\n",
      "[1540]\ttrain-error:0.12540\tvalid-error:0.13096\n",
      "[1550]\ttrain-error:0.12534\tvalid-error:0.13098\n",
      "[1560]\ttrain-error:0.12530\tvalid-error:0.13082\n",
      "[1570]\ttrain-error:0.12538\tvalid-error:0.13060\n",
      "[1580]\ttrain-error:0.12540\tvalid-error:0.13091\n",
      "[1590]\ttrain-error:0.12537\tvalid-error:0.13084\n",
      "[1600]\ttrain-error:0.12526\tvalid-error:0.13084\n",
      "[1610]\ttrain-error:0.12527\tvalid-error:0.13079\n",
      "[1620]\ttrain-error:0.12531\tvalid-error:0.13086\n",
      "[1630]\ttrain-error:0.12525\tvalid-error:0.13081\n",
      "[1640]\ttrain-error:0.12520\tvalid-error:0.13082\n",
      "[1650]\ttrain-error:0.12528\tvalid-error:0.13104\n",
      "[1660]\ttrain-error:0.12521\tvalid-error:0.13094\n",
      "[1670]\ttrain-error:0.12514\tvalid-error:0.13086\n",
      "[1680]\ttrain-error:0.12510\tvalid-error:0.13089\n",
      "[1690]\ttrain-error:0.12510\tvalid-error:0.13086\n",
      "[1700]\ttrain-error:0.12504\tvalid-error:0.13079\n",
      "[1710]\ttrain-error:0.12503\tvalid-error:0.13084\n",
      "[1720]\ttrain-error:0.12506\tvalid-error:0.13086\n",
      "[1730]\ttrain-error:0.12505\tvalid-error:0.13081\n",
      "[1740]\ttrain-error:0.12501\tvalid-error:0.13094\n",
      "[1750]\ttrain-error:0.12497\tvalid-error:0.13071\n",
      "[1760]\ttrain-error:0.12493\tvalid-error:0.13074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1770]\ttrain-error:0.12499\tvalid-error:0.13100\n",
      "[1780]\ttrain-error:0.12500\tvalid-error:0.13103\n",
      "[1790]\ttrain-error:0.12497\tvalid-error:0.13126\n",
      "[1800]\ttrain-error:0.12490\tvalid-error:0.13103\n",
      "[1810]\ttrain-error:0.12489\tvalid-error:0.13090\n",
      "[1820]\ttrain-error:0.12490\tvalid-error:0.13099\n",
      "[1830]\ttrain-error:0.12494\tvalid-error:0.13103\n",
      "[1840]\ttrain-error:0.12490\tvalid-error:0.13096\n",
      "[1850]\ttrain-error:0.12491\tvalid-error:0.13093\n",
      "[1860]\ttrain-error:0.12485\tvalid-error:0.13100\n",
      "[1870]\ttrain-error:0.12484\tvalid-error:0.13099\n",
      "[1880]\ttrain-error:0.12483\tvalid-error:0.13100\n",
      "[1890]\ttrain-error:0.12478\tvalid-error:0.13103\n",
      "[1900]\ttrain-error:0.12476\tvalid-error:0.13104\n",
      "[1910]\ttrain-error:0.12477\tvalid-error:0.13094\n",
      "[1920]\ttrain-error:0.12476\tvalid-error:0.13086\n",
      "[1930]\ttrain-error:0.12465\tvalid-error:0.13076\n",
      "[1940]\ttrain-error:0.12462\tvalid-error:0.13082\n",
      "[1950]\ttrain-error:0.12460\tvalid-error:0.13086\n",
      "[1960]\ttrain-error:0.12460\tvalid-error:0.13096\n",
      "[1970]\ttrain-error:0.12460\tvalid-error:0.13107\n",
      "[1980]\ttrain-error:0.12459\tvalid-error:0.13098\n",
      "[1990]\ttrain-error:0.12457\tvalid-error:0.13101\n",
      "[2000]\ttrain-error:0.12453\tvalid-error:0.13114\n",
      "[2010]\ttrain-error:0.12451\tvalid-error:0.13118\n",
      "[2020]\ttrain-error:0.12450\tvalid-error:0.13120\n",
      "[2030]\ttrain-error:0.12449\tvalid-error:0.13118\n",
      "[2040]\ttrain-error:0.12448\tvalid-error:0.13118\n",
      "[2050]\ttrain-error:0.12442\tvalid-error:0.13116\n",
      "[2060]\ttrain-error:0.12440\tvalid-error:0.13109\n",
      "[2070]\ttrain-error:0.12432\tvalid-error:0.13111\n",
      "[2080]\ttrain-error:0.12432\tvalid-error:0.13094\n",
      "[2090]\ttrain-error:0.12422\tvalid-error:0.13074\n",
      "[2100]\ttrain-error:0.12429\tvalid-error:0.13094\n",
      "[2110]\ttrain-error:0.12429\tvalid-error:0.13075\n",
      "[2120]\ttrain-error:0.12433\tvalid-error:0.13106\n",
      "[2130]\ttrain-error:0.12426\tvalid-error:0.13096\n",
      "[2140]\ttrain-error:0.12422\tvalid-error:0.13087\n",
      "[2150]\ttrain-error:0.12421\tvalid-error:0.13082\n",
      "[2160]\ttrain-error:0.12421\tvalid-error:0.13096\n",
      "[2170]\ttrain-error:0.12416\tvalid-error:0.13116\n",
      "[2180]\ttrain-error:0.12425\tvalid-error:0.13100\n",
      "[2190]\ttrain-error:0.12419\tvalid-error:0.13099\n",
      "[2200]\ttrain-error:0.12417\tvalid-error:0.13111\n",
      "[2210]\ttrain-error:0.12415\tvalid-error:0.13104\n",
      "[2220]\ttrain-error:0.12415\tvalid-error:0.13103\n",
      "[2230]\ttrain-error:0.12412\tvalid-error:0.13100\n",
      "[2240]\ttrain-error:0.12414\tvalid-error:0.13118\n",
      "[2250]\ttrain-error:0.12409\tvalid-error:0.13119\n",
      "[2260]\ttrain-error:0.12408\tvalid-error:0.13129\n",
      "[2270]\ttrain-error:0.12403\tvalid-error:0.13140\n",
      "[2280]\ttrain-error:0.12400\tvalid-error:0.13128\n",
      "[2290]\ttrain-error:0.12408\tvalid-error:0.13130\n",
      "[2300]\ttrain-error:0.12397\tvalid-error:0.13129\n",
      "[2310]\ttrain-error:0.12396\tvalid-error:0.13140\n",
      "[2320]\ttrain-error:0.12392\tvalid-error:0.13129\n",
      "[2330]\ttrain-error:0.12402\tvalid-error:0.13148\n",
      "[2340]\ttrain-error:0.12392\tvalid-error:0.13150\n",
      "[2350]\ttrain-error:0.12389\tvalid-error:0.13139\n",
      "[2360]\ttrain-error:0.12395\tvalid-error:0.13131\n",
      "[2370]\ttrain-error:0.12389\tvalid-error:0.13115\n",
      "[2380]\ttrain-error:0.12392\tvalid-error:0.13153\n",
      "[2390]\ttrain-error:0.12389\tvalid-error:0.13149\n",
      "[2400]\ttrain-error:0.12391\tvalid-error:0.13144\n",
      "[2410]\ttrain-error:0.12390\tvalid-error:0.13145\n",
      "[2420]\ttrain-error:0.12388\tvalid-error:0.13118\n",
      "[2430]\ttrain-error:0.12384\tvalid-error:0.13140\n",
      "[2440]\ttrain-error:0.12368\tvalid-error:0.13141\n",
      "[2450]\ttrain-error:0.12369\tvalid-error:0.13135\n",
      "[2460]\ttrain-error:0.12370\tvalid-error:0.13150\n",
      "[2470]\ttrain-error:0.12374\tvalid-error:0.13134\n",
      "[2480]\ttrain-error:0.12373\tvalid-error:0.13141\n",
      "[2490]\ttrain-error:0.12369\tvalid-error:0.13151\n",
      "[2500]\ttrain-error:0.12366\tvalid-error:0.13135\n",
      "[2510]\ttrain-error:0.12363\tvalid-error:0.13136\n",
      "[2520]\ttrain-error:0.12360\tvalid-error:0.13142\n",
      "[2530]\ttrain-error:0.12360\tvalid-error:0.13142\n",
      "[2540]\ttrain-error:0.12357\tvalid-error:0.13115\n",
      "[2550]\ttrain-error:0.12358\tvalid-error:0.13107\n",
      "[2560]\ttrain-error:0.12355\tvalid-error:0.13114\n",
      "[2570]\ttrain-error:0.12353\tvalid-error:0.13128\n",
      "[2580]\ttrain-error:0.12343\tvalid-error:0.13116\n",
      "[2590]\ttrain-error:0.12341\tvalid-error:0.13116\n",
      "[2600]\ttrain-error:0.12337\tvalid-error:0.13125\n",
      "[2610]\ttrain-error:0.12344\tvalid-error:0.13116\n",
      "[2620]\ttrain-error:0.12344\tvalid-error:0.13103\n",
      "[2630]\ttrain-error:0.12344\tvalid-error:0.13115\n",
      "[2640]\ttrain-error:0.12342\tvalid-error:0.13119\n",
      "[2650]\ttrain-error:0.12346\tvalid-error:0.13118\n",
      "[2660]\ttrain-error:0.12347\tvalid-error:0.13125\n",
      "[2670]\ttrain-error:0.12344\tvalid-error:0.13129\n",
      "[2680]\ttrain-error:0.12351\tvalid-error:0.13154\n",
      "[2686]\ttrain-error:0.12347\tvalid-error:0.13157\n",
      "Accuracy on test data: 88.555%\n"
     ]
    }
   ],
   "source": [
    "# Supported data_clean_type (DO NOT forget to put on \"()\", also, if data_clean_type is NOT empty string, please put a \" \" before (cleaned)):\n",
    "# empty string, no character\n",
    "# (cleaned)\n",
    "# (cleaned)(hyper_cleaned)\n",
    "# (cleaned)(hyper_cleaned)(punctuation_removed)\n",
    "# (cleaned)(hyper_cleaned)(punctuation_removed)(stopwords_removed)\n",
    "# (cleaned)(hyper_cleaned)(punctuation_removed)(stopwords_removed)(words_shortened)\n",
    "# (cleaned)(hyper_cleaned)(punctuation_removed)(stopwords_removed)(alternative_stopwords_used)\n",
    "# (cleaned)(hyper_cleaned)(punctuation_removed)(stopwords_removed)(alternative_stopwords_used)(words_shortened)\n",
    "data_clean_type = \" (cleaned)(hyper_cleaned)(punctuation_removed)(stopwords_removed)(alternative_stopwords_used)(words_shortened)\"\n",
    "train_df = pd.read_csv(\"train_with_features\" + data_clean_type + \".csv\")\n",
    "test_df = pd.read_csv(\"test_with_features\" + data_clean_type + \".csv\")\n",
    "\n",
    "xgb_model(train_df, test_df, data_clean_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
